{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, os.path\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/'\n",
    "images_path = './data/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQgJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcABwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD3+sy61f7LdLbPEu93CK2/5ec4zxntWkTtBJ6DmuU1C1GryXFw32i3ZRiMK5XdxncR688fSubEVXTiuXf9OppTipPU3NH1aLWbM3Vur+TvZFkYYEm04LKM5xnPX0rQrG8MvbLpSWdtB5KWwCbB/X365/PvWzW0JxnFSjszPllHSW4VzLWOpS69dLBcotufmLPGTg+g/wA9q6ailOmp2v0KjK1zE8NrOsNyJ8EiTapAxuHrjsfatuiiinTVOKignLmdz//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAADaklEQVR4Ab2UzW8TRxTAZ3bWu2vHHzHESxyvCSFREpcIqS1QEQStaLiglhNXpPYPQOKMKvUGBwS3tjm0Euq14kKlqKdKIUilLQUFiEisVEm8iR3Hjr02++H9mB0GHJk47O4B0c5h9d6beb95b96+Bwkh4H0v5n0DX/H+Xyh9Fsdx9uTRaNSWns/vMb6tsm+b2hbXdf96cJ9h4UBmKCmYGxuyiqPY1nIffAQsvVYtJtPDEEJPdxhQKIyxrmsPZ3+ayK6slUxx5KuDIyeNeuH6nZ9XV4q3Ll/t65c8oUFvihB60dSy0ZWU2KMoemVxxjX16bu3b8rW15eu7BcHPInUGASl26Za7O1xAIZGXWWspq5s/lrU+znh42wGMr6+vhvtKCK2nAAtUGueHe9lbFDY+HeJsFGeY1GQo2+h2lA3lpudu2tphdK2fWKCvfPnH7iFpi9eiAjh9gHPb9CF1KFPGk1NnIMDk2Onv8xmwLNi/trZqZOjo56sjjGo+lqjai59RxDDD34KEW/kfwszsspLGjspjXzOcahD2SP4RmoZDWf5e1xaABEJA0LLgpPj0HDjqpy2flmdv21ZeA+ro3pDbcs08j/EcX5hHWA+TusCARZ6+zU3+nih7mpkMPywlJ/xm0Xe0OpWsbiyuNY4fODoFxwnOLZttXQUYplE5uh47Mli3WqYuPo3djvBdQne1Y8nRfvDb8UD0tbaA8K8cF3sEgcR5ESHY+byoWx8rjCSzU0xDB2bHp3qDe15tYbUyiLe/N0OH0PEApA4ls0nUkp5f1qsccky6BcZn973Tp8mQ1NTl2eQXpbXKoAQFiBCTASxlcjVKuY+qJjlua6cdynekdIDLgFKVUkLxrxcUtVWMhnhWdaxla1Kc4wLQYgjwNzF6RJ9oSEEsHjm2aPpHmahUBE3hTjDsbRoLc1ICTqPoZ4Re7tQbxRfKD1y5JOppzBUvHejj1GHT30TS4qxREJrNmd/vLy0Tj47cfwNplsKgtLJPwAfjR2Pyvrg0JFjzOs6t0r/nJ8M6yZw1DJIpbtpO1oQVG3Um5qF2cHY4TNtInUylFUhmma5lu3qnkRqDOp9w2gV1mU+xEmSxLI7nV4orNa3t6jnaG4iLEQ8uUFQTwdqpM9CRwHyH9LvAvW7rGP3/fk7J95B+E+gLwHV63TPkNCgDwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test image conversion (RGBA with a=0 -> RGB with white background)\n",
    "# open the image and convert it to RGBA\n",
    "image = Image.open(images_path + 'dragonite.png').convert('RGBA')\n",
    "# convert to RGB with white background\n",
    "rgb_image = rgba_to_rgb_with_white_background(image)\n",
    "rgb_image = rgb_image.resize((28, 28))\n",
    "rgb_image.save('test.png')\n",
    "display(rgb_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "images = []\n",
    "labels = []\n",
    "for image_name in os.listdir(images_path):\n",
    "    # images\n",
    "    image = Image.open(images_path + image_name)\n",
    "    rgb_image = rgba_to_rgb_with_white_background(image)\n",
    "    rgb_image_small = rgb_image.resize((28,28),Image.LANCZOS)\n",
    "    image_array = np.asarray(rgb_image_small)\n",
    "    images.append(image_array)\n",
    "    all_images_array = np.stack(images, axis=0)\n",
    "    # labels\n",
    "    labels.append(np.zeros(18)) # 0 for now\n",
    "    all_labels_array = np.stack(labels, axis=0)\n",
    "    # save dataset\n",
    "    with open(data_path + 'images.npy', 'wb') as f:\n",
    "        np.save(f, all_images_array)\n",
    "    with open(data_path + 'labels.npy', 'wb') as f:\n",
    "        np.save(f, all_labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(809, 28, 28, 3)\n",
      "(809, 18)\n"
     ]
    }
   ],
   "source": [
    "# check dataset creation\n",
    "all_images_array = np.load(data_path + 'images.npy', mmap_mode=\"r\")\n",
    "all_labels_array = np.load(data_path + 'labels.npy', mmap_mode=\"r\")\n",
    "print(all_images_array.shape) # should be (809, 16, 16, 3)\n",
    "print(all_labels_array.shape) # should be (809, 18)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
