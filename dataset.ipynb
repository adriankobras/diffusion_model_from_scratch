{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, os.path\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/'\n",
    "images_path = './data/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQgJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD3+qV7qUdgx86J9m0sGUg5wMnvx/Krtc7ro/tK4WytbhY5lRvMLIHXacAjH5VhXqOELx36F048z12L8Gt202ox2GSbmWPzlRAW2x9mYjhc9q065DwxZw2esXs9zOZL2ULCuOFSNRhV+vGc9PSuvq6VSNSKlFkOMotqSt/l0CuW1a8j0nVkjFqyxzD5WjTJdiefrz2/xrqarS2MU93FcSbi0f3RnjPrU1oOcbIuEknqczbTRTeIrcPBLFM2GVZVKFhzk47gYzXX1UfT45NQS8LNvQYA7d/8at1NCj7LmXdjqT5reh//2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAD8klEQVR4AdWWS2gbRxzGd2dW+5B2JVkPW45k+R23aSznUNLiOpdSUyg9hUCgx9JCTrkEWuixhwZ66KEUem0LpRRCm0sPDnUhSWuIS5zYTqX4ITuOZFlvaaXVvnenGxxEwGjHGALtoMMws//vN9//m11EIoSIlznAyxR/pv1fBdRrZUPXj+Me42B/P9dsNgzDcLQsm7AsWxSb21vp9fVlEmBqD/Gke8h7T3ay2xnDMofiiRDxKL0rsdGZcEBIjp7mKCqzcssAXOr1t12sUC57ztbwyJjzKxX2nj64PjxB9QuGIAwNvzqH9NaPN7/5/H7uw1jsTGqWotleOseymVn5Y2aU8vH+9Ga7mLll6Mq9O79cWy8NjaY+ufqZi7pDxQOc1jOgRDM0YdrNcpNQJahLt/Olik7NxaIk2evoz9fxAEOVz4SqhGETUuej+QRPgVat9KAt2TQLMeLPtjEZOE+QTpi7ZIjIIwKms61QOKpnV5cqyvlQ4oPzb2AReAcMTU+88+nfxcHfM5zITqTG4Xe3FywU/Ony5fFYDAvAO1Dkjl5Zmrtw1oQRTuDI8uL8VOFNfyhIH6dDBOY9UOWOtPaVoKfVkYtMX5KE3uo/i3G4TvBcTvTInvnx6fcoV5Bbi3RNVrPfUs3HuVof4MKK1LZ0mT11ttmCB1vSEJRjxM2tlRvONXMZPQHOV6G18X3QWqu2zKLKAUhwHIuQCRnWYgeqLfnho0aAYwfIxUJ2+SSAZqNe3rm/X0BK6N34+BRCwLScYXogMLynpif9OrLzm/UgKevley6AniEzLKslP4aRyFg4Xtr6FZBAN1SEbA8NqL6xxs7D1FTgzhpal88lJmdcAJiQncryxm8d5cDfH7dN03nxIaAplpe2/xy0MnbQn668MjV7haZ6trrnxuGhaoUtKn+jXm47B6GcASiELEtVqchkvU1A0xoilxulTRcHGEDrIBOgDKXZ2Hhc6EgaQUJAIgIZNuCedqK2ovAem5LzLoCeGRzWyDpdLCoD3tpqgWvUJI4lWecWGbYoyT5dAwAi3USu1xQDGJ6+cDe9FKiveZRqFUUZIUbAtk/wATos7q/m9lDHAJGxURcH+JAVzbr78xdU9S/DE5q5+CXNsD6/wNDMwg/XGxsL3kTq/Stfg94fbYwD52habXM2+QTGQ7vWuVg88bx1kpgaKASSyUJT67RFwR/oZQITsvOvrJJdQh5Og0z/5FtdlU5l08+1GZ7r82umJnbXj06wDpAVnd1VX/PSnpHEdLcecYMZcMljEICHp/2R7vrRCT4DXdc1TfPxwouNtm0ktkRVVXmeF3j+qG53BQ/oPnqyCSaDk4m+WPX/B/wLgz/G4uu1Fs8AAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test image conversion (RGBA with a=0 -> RGB with white background)\n",
    "# open the image and convert it to RGBA\n",
    "image = Image.open(images_path + 'dragonite.png').convert('RGBA')\n",
    "# convert to RGB with white background\n",
    "rgb_image = rgba_to_rgb_with_white_background(image)\n",
    "rgb_image = rgb_image.resize((32, 32))\n",
    "display(rgb_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dragonite is a Dragon and Flying type pokemon\n",
      "[0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "name = \"dragonite\"\n",
    "type1, type2 = get_types_from_csv(name, data_path + 'pokemon.csv')\n",
    "print(f'{name} is a {type1} and {type2} type pokemon')\n",
    "encoded = encode_type(type1, type2)\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "images = []\n",
    "labels = []\n",
    "for image_name in os.listdir(images_path):\n",
    "    # images\n",
    "    image = Image.open(images_path + image_name)\n",
    "    rgb_image = rgba_to_rgb_with_white_background(image)\n",
    "    rgb_image_small = rgb_image.resize((32,32),Image.LANCZOS)\n",
    "    image_array = np.asarray(rgb_image_small)\n",
    "    images.append(image_array)\n",
    "    all_images_array = np.stack(images, axis=0)\n",
    "    # labels\n",
    "    pokemon_name = image_name.split(\".\")[0]\n",
    "    type1, type2 = get_types_from_csv(pokemon_name, data_path + 'pokemon.csv')\n",
    "    encoded_pokemon_name = encode_type(type1, type2)\n",
    "    labels.append(encoded_pokemon_name)\n",
    "    all_labels_array = np.stack(labels, axis=0)\n",
    "    # save dataset\n",
    "    with open(data_path + 'images.npy', 'wb') as f:\n",
    "        np.save(f, all_images_array)\n",
    "    with open(data_path + 'labels.npy', 'wb') as f:\n",
    "        np.save(f, all_labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(809, 32, 32, 3)\n",
      "(809, 18)\n"
     ]
    }
   ],
   "source": [
    "# check dataset creation\n",
    "all_images_array = np.load(data_path + 'images.npy', mmap_mode=\"r\")\n",
    "all_labels_array = np.load(data_path + 'labels.npy', mmap_mode=\"r\")\n",
    "print(all_images_array.shape) # should be (809, 28, 28, 3) for image size 28x28\n",
    "print(all_labels_array.shape) # should be (809, 18)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
